{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install cloudscraper beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import cloudscraper\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "from unidecode import unidecode\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(soup):\n",
    "    canonical_tag = soup.find('link', rel='canonical')\n",
    "    # Lấy giá trị của thuộc tính href\n",
    "    if canonical_tag and 'href' in canonical_tag.attrs:\n",
    "        canonical_url = canonical_tag['href']\n",
    "        return canonical_url\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_company(soup):\n",
    "    temp = get_url(soup)\n",
    "    if temp:\n",
    "        # Regex\n",
    "        pattern = r\"\\/(\\d+)(?=\\.html)\"\n",
    "        match = re.search(pattern, temp)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_company(soup):\n",
    "    data = soup.find(\"div\", class_=\"box-detail\")\n",
    "    if data:\n",
    "        ten_cong_ty = data.find('h1').text\n",
    "        return ten_cong_ty\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_web_company(soup):\n",
    "    try:\n",
    "        website_tag = \"\"\n",
    "        # Tìm thẻ <a> chứa link website\n",
    "        website_tag = soup.find(\"div\", class_=\"company-subdetail-info website\")\n",
    "        if website_tag:\n",
    "            website_tag = website_tag.find(\"a\")\n",
    "            return website_tag.get(\"href\")\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return f\"Lỗi: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_logo(soup):\n",
    "    try:\n",
    "        # Tìm tag chứa ảnh logo\n",
    "        img_tag = soup.find(\"div\", class_=\"company-image-logo\").find(\"img\")\n",
    "        if not img_tag:\n",
    "            return None\n",
    "        \n",
    "        # Lấy link logo\n",
    "        logo_url = img_tag.get(\"src\")\n",
    "        output_folder=\"logos\"\n",
    "        logo_url = urljoin('https://cdn-new.topcv.vn', logo_url)  # Hoàn thiện URL\n",
    "        # print(logo_url)\n",
    "        # Lấy id công ty\n",
    "        company_id = get_id_company(soup)  # Hàm này do bạn cung cấp\n",
    "        \n",
    "        # Tạo tên file và thư mục lưu\n",
    "        filename = f\"logo_{company_id}.jpg\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        file_path = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # Tải ảnh từ link\n",
    "        response = requests.get(logo_url, stream=True)\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        return logo_url\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Lỗi: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_size(soup):\n",
    "    try:     \n",
    "        # Lọc tất cả các thẻ có class \"company-subdetail-info\"\n",
    "        size_tags = soup.find_all(\"div\", class_=\"company-subdetail-info\")\n",
    "        for tag in size_tags:\n",
    "            if \"nhân viên\" in (tag.text).lower():\n",
    "                return tag.find(\"span\", class_=\"company-subdetail-info-text\").text.strip()\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return f\"Lỗi: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_intro(soup):\n",
    "    try:\n",
    "        # Tìm thẻ chứa nội dung chính của công ty\n",
    "        content_div = soup.find(\"div\", class_=\"content\")\n",
    "        \n",
    "        # Kiểm tra nếu thẻ <div> tồn tại\n",
    "        if content_div:\n",
    "            # Lấy tất cả các thẻ <p> bên trong\n",
    "            paragraphs = content_div.find_all(\"p\")\n",
    "            return \"\\n\".join(p.text.strip() for p in paragraphs)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Lỗi: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_address(soup):\n",
    "    try:\n",
    "        # Tìm tất cả các mục có class=\"item\"\n",
    "        items = soup.find_all(\"div\", class_=\"item\")\n",
    "        \n",
    "        # Duyệt qua từng mục để tìm \"Địa chỉ công ty\"\n",
    "        for item in items:\n",
    "            # Tìm phần tử có class=\"box-caption\" và text là \"Địa chỉ công ty\"\n",
    "            caption = item.find(\"div\", class_=\"box-caption\")\n",
    "            if caption and \"địa chỉ công ty\" in (caption.get_text(strip=True)).lower():\n",
    "                # Nếu tìm thấy, lấy nội dung từ class=\"desc\"\n",
    "                address = item.find(\"div\", class_=\"desc\")\n",
    "                if address:\n",
    "                    return address.get_text(strip=True)  # Trả về địa chỉ sạch\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Lỗi: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Đường dẫn tới file JSON\n",
    "file_path = 'data_26_11_sample.json'\n",
    "\n",
    "# Đọc file JSON\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Hiển thị dữ liệu đã đọc\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UrlCongTy = []\n",
    "for temp in data:\n",
    "    UrlCongTy.append(temp.get('UrlCongTy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "# Đọc file Excel\n",
    "output = []\n",
    "for temp in UrlCongTy:\n",
    "    while True:\n",
    "        try:\n",
    "            scraper = cloudscraper.create_scraper(\n",
    "                        browser={\n",
    "                            \"browser\": \"chrome\",\n",
    "                            \"platform\": \"windows\",\n",
    "                        },\n",
    "                    )\n",
    "            # specify the target URL\n",
    "            url = temp\n",
    "            response = scraper.get(url)\n",
    "            print(response.status_code)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                if get_id_company(soup):\n",
    "                    data = {\n",
    "                        'Url': str(get_url(soup)),\n",
    "                        'ID': int(get_id_company(soup)),\n",
    "                        'Logo': str(save_logo(soup)),\n",
    "                        'Name': str(get_name_company(soup)),\n",
    "                        'CompanyWebsite': str(get_web_company(soup)),\n",
    "                        'CompanySize': str(get_company_size(soup)),\n",
    "                        'CompanyIntroduction': str(get_company_intro(soup)),\n",
    "                        'CompanyAddress': str(get_company_address(soup))\n",
    "                    }\n",
    "                    output.append(data)\n",
    "\n",
    "                    print(response.status_code, \"Cập nhật thông tin thành công.\", get_id_company(soup), len(output))\n",
    "            if response.status_code == 429:\n",
    "                # print(f\"ID {ids}: Too many requests, retrying...\")\n",
    "                time.sleep(random.randint(1, 5))  # Chờ một khoảng thời gian trước khi thử lại\n",
    "            else:\n",
    "                break  # Thoát khỏi vòng lặp nếu không phải 429\n",
    "        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:\n",
    "            print(f\"ID {get_id_company(soup)}: Lỗi kết nối {e}. Đang thử lại...\")\n",
    "            time.sleep(random.randint(1, 5))  # Chờ thêm trước khi thử lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Hàm để xử lý kiểu dữ liệu không serializable\n",
    "def default_converter(o):\n",
    "    if isinstance(o, (np.integer, np.floating)):  # Xử lý kiểu số NumPy\n",
    "        return int(o)\n",
    "    elif isinstance(o, (np.ndarray,)):           # Xử lý mảng NumPy (nếu có)\n",
    "        return o.tolist()\n",
    "    return str(o)  # Xử lý các kiểu dữ liệu khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu vào tệp JSON\n",
    "with open(\"data_26_11_sample_cong_ty.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(output, json_file, ensure_ascii=False, default=default_converter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Minh-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
